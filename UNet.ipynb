{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/svakeczw/Semantic-Image-Segmentation-UNet/blob/main/UNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PNtP8EaMWG-N"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1M7Y6KJeWSqX"
   },
   "outputs": [],
   "source": [
    "dataset, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CuxOAxohjzEz"
   },
   "source": [
    "#Image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8YsPC6QDWhPH"
   },
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "def random_flip(input_image, input_mask):\n",
    "  if tf.random.uniform(shape=(), minval=0, maxval=1) > 0.5:\n",
    "    input_image = tf.image.flip_left_right(image=input_image)\n",
    "    input_mask = tf.image.flip_left_right(image=input_mask)\n",
    "  return input_image, input_mask\n",
    "\n",
    "def normalize(input_image, input_mask):\n",
    "  input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "  input_mask = input_mask - 1  # the pixel value for mask is [1,3] and convert to [0,2]\n",
    "  return input_image, input_mask\n",
    "\n",
    "def load_image_train(datapoint):\n",
    "  input_image = tf.image.resize(datapoint['image'],size=(128,128))\n",
    "  input_mask = tf.image.resize(datapoint['segmentation_mask'], size=(128,128))\n",
    "  input_image, input_mask = random_flip(input_image, input_mask)\n",
    "  input_image, input_mask = normalize(input_image, input_mask)\n",
    "  return input_image, input_mask\n",
    "\n",
    "def load_image_test(datapoint):\n",
    "  input_image = tf.image.resize(datapoint['image'],size=(128,128))\n",
    "  input_mask = tf.image.resize(datapoint['segmentation_mask'], size=(128,128))\n",
    "  input_image, input_mask = normalize(input_image, input_mask)\n",
    "  return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQ74jUFiWyyt"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train = dataset['train'].map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_dataset = train.cache()\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1000)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "train_dataset = train_dataset.repeat()\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "test = dataset['test'].map(load_image_test)\n",
    "test_dataset = test.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8YBUfVftXBSE"
   },
   "outputs": [],
   "source": [
    "def display_image(image_list, titles=[]):\n",
    "  plt.figure(figsize=(15,15))\n",
    "  for i in range(len(image_list)):\n",
    "    plt.subplot(1, len(image_list), i+1)\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    img_arr = tf.keras.preprocessing.image.array_to_img(image_list[i])\n",
    "    plt.imshow(img_arr)\n",
    "  plt.show()\n",
    "\n",
    "def show_dataset(dataset):\n",
    "  for image, mask in dataset.take(1):\n",
    "    display_image([image, mask], titles=['image', 'mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9WtlPXopXGfR"
   },
   "outputs": [],
   "source": [
    "show_dataset(train)\n",
    "show_dataset(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R56zsJHLXP34"
   },
   "source": [
    "# UNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gKGXeagFXMQ5"
   },
   "outputs": [],
   "source": [
    "# Encoder part\n",
    "def conv2d_block(input_tensor, num_filters, kernel_size=3):\n",
    "  x = input_tensor\n",
    "  for i in range(2):\n",
    "    x = tf.keras.layers.Conv2D(filters=num_filters, kernel_size=(kernel_size, kernel_size), padding='same')(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "  return x\n",
    "\n",
    "def encoder_block(input_tensor, num_filters, pooling_size=(2,2), stride_size=2):\n",
    "  f = conv2d_block(input_tensor, num_filters=num_filters)  # feature output\n",
    "  p = tf.keras.layers.MaxPool2D(pool_size=pooling_size,strides=stride_size)(f)  # pooling output\n",
    "  p = tf.keras.layers.Dropout(0.3)(p)\n",
    "  return f, p\n",
    "\n",
    "def encoder(input_tensor):\n",
    "  x = input_tensor\n",
    "  f1, p1 = encoder_block(x, num_filters=64)\n",
    "  f2, p2 = encoder_block(p1, num_filters=128)\n",
    "  f3, p3 = encoder_block(p2, num_filters=256)\n",
    "  f4, output = encoder_block(p3, num_filters=512)\n",
    "\n",
    "  return output, (f1, f2, f3, f4)\n",
    "\n",
    "def bottom_layer(input_tensor):\n",
    "  x = conv2d_block(input_tensor=input_tensor, num_filters=1024)\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PQvv9okoXZMY"
   },
   "outputs": [],
   "source": [
    "# Decoder part\n",
    "def decoder_block(input_tensor, conv_output, num_filters):\n",
    "  out = tf.keras.layers.Conv2DTranspose(filters=num_filters, kernel_size=2, padding='same', strides=2)(input_tensor)\n",
    "  out = tf.keras.layers.concatenate([conv_output, out])\n",
    "  out = tf.keras.layers.Dropout(0.3)(out)\n",
    "  out = conv2d_block(out,num_filters=num_filters, kernel_size=3)\n",
    "  return out\n",
    "\n",
    "def decoder(input_tensor, encoder_out_f, output_channels=3):\n",
    "  f1, f2, f3, f4 = encoder_out_f\n",
    "\n",
    "  de4 = decoder_block(input_tensor, conv_output=f4, num_filters=512)\n",
    "  de3 = decoder_block(de4, conv_output=f3, num_filters=256)\n",
    "  de2 = decoder_block(de3, conv_output=f2, num_filters=128)\n",
    "  de1 = decoder_block(de2, conv_output=f1, num_filters=64)\n",
    "\n",
    "  output = tf.keras.layers.Conv2D(filters=output_channels, kernel_size=(1,1), activation='softmax')(de1)\n",
    "\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Utgu9BBTX9Ux"
   },
   "outputs": [],
   "source": [
    "def unet():\n",
    "\n",
    "  inputs = tf.keras.layers.Input(shape=(128, 128,3))\n",
    "\n",
    "  encoder_outputs, encoder_out_f = encoder(inputs)\n",
    "\n",
    "  bottom_outputs = bottom_layer(encoder_outputs)\n",
    "\n",
    "  outputs = decoder(bottom_outputs, encoder_out_f, output_channels=3)\n",
    "\n",
    "  model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2xS-s8-HYEs0"
   },
   "outputs": [],
   "source": [
    "unet_model = unet()\n",
    "unet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jc3czp7cYL6q"
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(unet_model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jYj2y9iWYR_k"
   },
   "outputs": [],
   "source": [
    "unet_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "epochs = 50\n",
    "num_train = info.splits['train'].num_examples\n",
    "num_test = info.splits['test'].num_examples\n",
    "num_valid = num_test * 0.2\n",
    "\n",
    "model_history = unet_model.fit(\n",
    "    train_dataset, epochs=epochs, steps_per_epoch=num_train//batch_size, \n",
    "    validation_steps= num_valid//batch_size, validation_data=test_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z2syKCAeYZ6P"
   },
   "outputs": [],
   "source": [
    "def plot_metrics(metric_name, title):\n",
    "  plt.figure()\n",
    "  plt.title(title)\n",
    "  plt.ylim(bottom=0, top=1)\n",
    "  plt.plot(model_history.history[metric_name],color='blue', label=metric_name)\n",
    "  plt.plot(model_history.history['val_'+metric_name], color='green', label='val'+metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fK11m0dIYfvn"
   },
   "outputs": [],
   "source": [
    "plot_metrics(metric_name='loss', title='Train-Valid loss')\n",
    "plot_metrics('accuracy', 'Train-Valid accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XP1xoH6rYsxT"
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AeKtq0uoYmc6"
   },
   "outputs": [],
   "source": [
    "def create_mask(pred_mask):\n",
    "  pred_mask = tf.argmax(pred_mask,axis=-1)\n",
    "  pred_mask = pred_mask[...,tf.newaxis]\n",
    "  return pred_mask[0].numpy()\n",
    "\n",
    "def make_prediction(image):\n",
    "  image = image[tf.newaxis,:]\n",
    "  pred_mask = unet_model.predict(image)\n",
    "  pred_mask = create_mask(pred_mask)\n",
    "  return pred_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dDMT2v1gY4Ii"
   },
   "outputs": [],
   "source": [
    "def class_wise_metrics(y_true, y_pred):\n",
    "  iou_list = []  # Contain three classes' iou\n",
    "  dice_score_list = []  # Contain three classes' dice score\n",
    "  smoothening_factor = 1e-10\n",
    "\n",
    "  for i in range(3):\n",
    "    y_true_area = np.sum(y_true == i)\n",
    "    y_pred_area = np.sum(y_pred == i)\n",
    "\n",
    "    intersection = np.sum((y_pred == i) * (y_true == i))\n",
    "    combined_area = y_true_area + y_pred_area\n",
    "\n",
    "    iou = (intersection + smoothening_factor) / (combined_area - intersection + smoothening_factor)\n",
    "    iou_list.append(iou)\n",
    "\n",
    "    dice_score = 2 * (\n",
    "        (intersection + smoothening_factor) / (combined_area + smoothening_factor)\n",
    "    )\n",
    "    dice_score_list.append(dice_score)\n",
    "  \n",
    "  return iou_list, dice_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fpT1FFdDY73X"
   },
   "outputs": [],
   "source": [
    "def unpack_test_dataset():\n",
    "\n",
    "  num_test = info.splits['test'].num_examples\n",
    "  ds = test_dataset.unbatch()\n",
    "  ds = ds.batch(num_test)\n",
    "  \n",
    "  images = []\n",
    "  y_true_segments = []\n",
    "\n",
    "  for image, mask in ds.take(1):\n",
    "    y_true_mask = mask.numpy()\n",
    "    images = image.numpy()\n",
    "  \n",
    "  y_true_mask = y_true_mask[:(num_test - (num_test % batch_size))]\n",
    "  images = images[:(num_test - (num_test % batch_size))]\n",
    "  return image, y_true_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_KGoAB-jZKXH"
   },
   "outputs": [],
   "source": [
    "def get_predict_by_idx(idx=0):\n",
    "  images, y_true_mask = unpack_test_dataset()\n",
    "  image = images[idx]\n",
    "  image = image[tf.newaxis,:]\n",
    "  y_pred = unet_model.predict(image)\n",
    "  y_pred = np.argmax(y_pred, axis=3)\n",
    "  y_pred = y_pred[...,tf.newaxis]\n",
    "  y_mask = y_true_mask[idx]\n",
    "  iou_list, dice_score_list = class_wise_metrics(y_true=y_mask,y_pred=y_pred)\n",
    "  return image, y_mask, y_pred, iou_list, dice_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l2TT5NtrZRrn"
   },
   "outputs": [],
   "source": [
    "def show_prediction_with_metric(image, y_mask, y_pred, iou_list, dice_score_list):\n",
    "  class_name = ['Pet', 'Background', 'Outline']\n",
    "  image = tf.squeeze(image)  # Remove batch dim\n",
    "  y_pred = y_pred[0]  # Remove batch dim\n",
    "  display_list = [image, y_mask, y_pred]\n",
    "  title = ['Image', 'True mask', 'Pred mask']\n",
    "  metric_string = [f'{name}: iou: {iou} : dice: {dice}' for _, (name, iou, dice) in enumerate(zip(class_name, iou_list, dice_score_list))]\n",
    "  metric_string = '\\n\\n'.join(metric_string)\n",
    "  plt.figure(figsize=(15,15))\n",
    "  for i in range(len(display_list)):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.title(title[i])\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "    if i == 1:\n",
    "      plt.xlabel(metric_string ,fontsize=15)  \n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PmC1l9ewZeGM"
   },
   "outputs": [],
   "source": [
    "image, y_mask, y_pred, iou_list, dice_score_list = get_predict_by_idx(16)\n",
    "show_prediction_with_metric(image, y_mask, y_pred, iou_list, dice_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1d3uDxSvm0JQ"
   },
   "outputs": [],
   "source": [
    "# Show overlapped image\n",
    "def over_lap(image, y_pred):\n",
    "  bottom = image[0].numpy()\n",
    "  top = np.array(y_pred[0],dtype=np.float32)\n",
    "  top = np.concatenate((top,top,top), axis=-1)\n",
    "  top[:,:,0] = tf.where(top[:,:,0]==0, top[:,:,0]+0.1, top[:,:,0])\n",
    "  top[:,:,1] = tf.where(top[:,:,1]==0, top[:,:,1]+0.1, top[:,:,1])\n",
    "  top[:,:,2] = tf.where(top[:,:,2]==0, top[:,:,2]+2, top[:,:,2])\n",
    "  overlapped_image = cv2.addWeighted(src1=bottom, alpha=0.6, src2=top, beta=0.2, gamma=0.2)\n",
    "  overlapped_image = tf.clip_by_value(overlapped_image,0,1)\n",
    "  plt.imshow(overlapped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VpDLinGGrhbO"
   },
   "outputs": [],
   "source": [
    "over_lap(image, y_pred)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNZzdT39mrei/Hk1q4qeFTQ",
   "include_colab_link": true,
   "name": "UNet.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}